{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22476a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:39:55.195667Z",
     "start_time": "2024-03-19T20:39:41.519834Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import iris\n",
    "import tobac\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import Counter\n",
    "from global_land_mask import globe\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cmaps\n",
    "import netCDF4 as nc \n",
    "import warnings\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import logging\n",
    "#from skimage.morphology import binary_erosion\n",
    "import multiprocessing\n",
    "import concurrent\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm, notebook\n",
    "import pickle\n",
    "import multiprocessing as mp\n",
    "from itertools import repeat,product\n",
    "from dask.array import ma, isin\n",
    "from copy import deepcopy\n",
    "# Ignore some warnings and append them to the existing filter list\n",
    "warnings.filterwarnings('ignore', category=UserWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, append=True)\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37bb03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:39:55.225402Z",
     "start_time": "2024-03-19T20:39:55.197688Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the 'caffeine' module to prevent the system from going to sleep or the screen from turning off\n",
    "import caffeine\n",
    "# Turn on the caffeine mode with the display option set to True\n",
    "caffeine.on(display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149dfa1",
   "metadata": {},
   "source": [
    "# Load the data for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90361a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:39:56.285408Z",
     "start_time": "2024-03-19T20:39:55.227757Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "year = 2017\n",
    "# Load the dataframe that contains feature (convective system) information\n",
    "data = pd.read_hdf(f\"/Volumes/Pegasus32 R8/NASA/PROCESSED_TOBAC_NO_NA/{year}/Track.h5\",key='/table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d6475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:40:25.226230Z",
     "start_time": "2024-03-19T20:39:56.287711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove cells (convective families) that have only one feature (convective system) in them\n",
    "data = data.groupby('cell').filter(lambda x : (x['cell'].count()>1)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a957df9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:40:25.274852Z",
     "start_time": "2024-03-19T20:40:25.227946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove redundant columms\n",
    "data = data.drop(columns=['idx','hdim_1','hdim_2','num','threshold_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf9afef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:40:25.279642Z",
     "start_time": "2024-03-19T20:40:25.276789Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rename 'time' column\n",
    "data.rename(columns = {'time':'datetime'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6dcc93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:40:25.809014Z",
     "start_time": "2024-03-19T20:40:25.281198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the 'datetime' column values to a pandas datetime type\n",
    "data['timestr'] = pd.to_datetime(data['timestr'])\n",
    "\n",
    "# Split datetime column into separate columns\n",
    "data['year'] = data['timestr'].dt.year\n",
    "data['month'] = data['timestr'].dt.month\n",
    "data['day'] = data['timestr'].dt.day\n",
    "data['time'] = data['timestr'].dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da9f091",
   "metadata": {},
   "source": [
    "# Loading pixel level information for every feature (convective system)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8747d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:43:29.782472Z",
     "start_time": "2024-03-19T20:40:25.810747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dictionary from 'tb_dict.pkl' file\n",
    "with open(f\"/Volumes/Pegasus32 R8/NASA/PICKLES_WITH_TB_VALUES_NO_NA/{year}/tb_dict.pkl\", 'rb') as handle:\n",
    "    tb_dict = pickle.load(handle)\n",
    "\n",
    "# Load the dictionary from 'tau_dict.pkl' file\n",
    "with open(f\"/Volumes/Pegasus32 R8/NASA/PICKLES_WITH_TB_VALUES_NO_NA/{year}/tau_dict.pkl\", 'rb') as handle:\n",
    "    tau_dict = pickle.load(handle)\n",
    "\n",
    "# Load the dictionary from 'lats_dict.pkl' file\n",
    "with open(f\"/Volumes/Pegasus32 R8/NASA/PICKLES_WITH_TB_VALUES_NO_NA/{year}/lats_dict.pkl\", 'rb') as handle:\n",
    "    lats_dict = pickle.load(handle)\n",
    "\n",
    "# Load the dictionary from 'lons_dict.pkl' file\n",
    "with open(f\"/Volumes/Pegasus32 R8/NASA/PICKLES_WITH_TB_VALUES_NO_NA/{year}/lons_dict.pkl\", 'rb') as handle:\n",
    "    lons_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe774e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:43:51.150272Z",
     "start_time": "2024-03-19T20:43:29.787708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace -1000 with np.nan in dictionary values\n",
    "for key, value_list in tb_dict.items():\n",
    "    tb_dict[key] = [np.nan if item == -1000 else item for item in value_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef31fb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:44:12.294353Z",
     "start_time": "2024-03-19T20:43:51.154931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace -1000 with np.nan in dictionary values\n",
    "for key, value_list in tau_dict.items():\n",
    "    tau_dict[key] = [np.nan if item == -1000 else item for item in value_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99228bbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:44:33.482967Z",
     "start_time": "2024-03-19T20:44:12.295784Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace -1000 with np.nan in dictionary values\n",
    "for key, value_list in lons_dict.items():\n",
    "    lons_dict[key] = [np.nan if item == -1000 else item for item in value_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20f2cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:45:06.834146Z",
     "start_time": "2024-03-19T20:44:33.484595Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace -1000 with np.nan in dictionary values\n",
    "for key, value_list in lats_dict.items():\n",
    "    lats_dict[key] = [np.nan if item == -1000 else item for item in value_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80458ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:45:11.639744Z",
     "start_time": "2024-03-19T20:45:06.835907Z"
    }
   },
   "outputs": [],
   "source": [
    "# The map function takes each value from the 'feature' column, \n",
    "# looks it up in the dictionary, and returns the corresponding value from the dictionary \n",
    "data['TB'] = data.feature.map(tb_dict)\n",
    "data['TAU'] = data.feature.map(tau_dict)\n",
    "data['pixel_lons'] = data.feature.map(lons_dict)\n",
    "data['pixel_lats'] = data.feature.map(lats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73233f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:45:12.049618Z",
     "start_time": "2024-03-19T20:45:11.641818Z"
    }
   },
   "outputs": [],
   "source": [
    "del tb_dict\n",
    "del tau_dict\n",
    "del lons_dict\n",
    "del lats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970db07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:45:12.054413Z",
     "start_time": "2024-03-19T20:45:12.052212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Columns to replace empty lists with NaN\n",
    "columns_to_replace = ['TB', 'TAU', 'pixel_lons', 'pixel_lats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262598d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:45:12.059205Z",
     "start_time": "2024-03-19T20:45:12.056597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to replace empty lists with NaN\n",
    "def replace_empty_with_nan(lst):\n",
    "    return np.nan if isinstance(lst, list) and len(lst) == 0 else lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d613a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-19T20:45:13.166446Z",
     "start_time": "2024-03-19T20:45:12.060922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the replacement function to selected columns\n",
    "for column in columns_to_replace:\n",
    "    data[column] = data[column].apply(replace_empty_with_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13424e8",
   "metadata": {},
   "source": [
    "# Performing aggregation and creating summary statistics of various parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951b66f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:04:31.797266Z",
     "start_time": "2023-12-10T13:04:31.290702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to calculate length of each list or add nan\n",
    "def calculate_length_or_nan(lst):\n",
    "    if isinstance(lst, list):\n",
    "        length = int(len(lst))\n",
    "        return length\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to the column and create a new column\n",
    "data['pixel_count'] = data['TB'].apply(calculate_length_or_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ab86a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:05:17.277216Z",
     "start_time": "2023-12-10T13:04:31.799070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a threshold\n",
    "threshold = 220\n",
    "\n",
    "# Custom function to count values below a certain threshold\n",
    "def count_below_threshold(lst):\n",
    "    if isinstance(lst, list):\n",
    "        return sum(1 for value in lst if value <= threshold)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "# Create a new column with the count of values below the threshold\n",
    "data['pixels_below_220'] = data['TB'].apply(count_below_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57639896",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:05:35.070865Z",
     "start_time": "2023-12-10T13:05:17.286326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a threshold\n",
    "threshold = 200\n",
    "\n",
    "# Custom function to count values below a certain threshold\n",
    "def count_below_threshold(lst):\n",
    "    if isinstance(lst, list):\n",
    "        return sum(1 for value in lst if value <= threshold)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Create a new column with the count of values below the threshold\n",
    "data['pixels_below_200'] = data['TB'].apply(count_below_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ab849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:05:35.284901Z",
     "start_time": "2023-12-10T13:05:35.072906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculation convective fraction\n",
    "data['convective_fraction'] = data['pixels_below_220']/data['pixel_count']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b8102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:05:37.731251Z",
     "start_time": "2023-12-10T13:05:35.292724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sort values by 'cell' number (convective family) and time step of each convective system within convective family\n",
    "data = data.sort_values(by=['cell','time_cell']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b504a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:06:25.295891Z",
     "start_time": "2023-12-10T13:05:37.736474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find minimum brightnesss temperature of each CS (convectvie system)\n",
    "data['minTB_feature'] = data['TB'].apply(np.nanmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478544e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:06:25.425900Z",
     "start_time": "2023-12-10T13:06:25.297372Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find minimum brightnesss temperature of each convective family\n",
    "dfc = data.groupby('cell')['minTB_feature']\n",
    "data['minTB_cell' ] = dfc.transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d326a38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:07:20.410222Z",
     "start_time": "2023-12-10T13:06:25.433124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find average brightnesss temperature of each CS (convectvie system)\n",
    "data['avgTB_feature'] = data['TB'].apply(np.nanmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4162c00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:09:36.994783Z",
     "start_time": "2023-12-10T13:07:20.411767Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find average brightnesss temperature of each convective family\n",
    "dfc = data.groupby('cell')['avgTB_feature']\n",
    "data['avgTB_cell' ] = dfc.transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7913bba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:10:57.438318Z",
     "start_time": "2023-12-10T13:09:37.010124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find maximum brightnesss temperature of each CS (convectvie system)\n",
    "data['maxTB_feature'] = data['TB'].apply(np.nanmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fce964",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:10:57.730513Z",
     "start_time": "2023-12-10T13:10:57.506683Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find maximum brightnesss temperature of each convective family\n",
    "dfc = data.groupby('cell')['maxTB_feature']\n",
    "data['maxTB_cell' ] = dfc.transform('max')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112e58c",
   "metadata": {},
   "source": [
    "# Calculate percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb93cc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:10:57.861014Z",
     "start_time": "2023-12-10T13:10:57.732505Z"
    }
   },
   "outputs": [],
   "source": [
    "tb = data['TB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd1e364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:12:56.454800Z",
     "start_time": "2023-12-10T13:10:57.862936Z"
    }
   },
   "outputs": [],
   "source": [
    "tenth = [np.nanpercentile(i, 10) for i in tqdm(tb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20689744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:12:56.969169Z",
     "start_time": "2023-12-10T13:12:56.456544Z"
    }
   },
   "outputs": [],
   "source": [
    "data['10th'] = tenth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c369a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:14:48.711044Z",
     "start_time": "2023-12-10T13:12:56.977163Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twentyfifth = [np.nanpercentile(i, 25) for i in tqdm(tb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36169b27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:14:49.187250Z",
     "start_time": "2023-12-10T13:14:48.712676Z"
    }
   },
   "outputs": [],
   "source": [
    "data['25th'] = twentyfifth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a6a37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:16:41.925729Z",
     "start_time": "2023-12-10T13:14:49.189003Z"
    }
   },
   "outputs": [],
   "source": [
    "fifty = [np.nanpercentile(i, 50) for i in tqdm(tb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f44e60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:16:42.460409Z",
     "start_time": "2023-12-10T13:16:41.927571Z"
    }
   },
   "outputs": [],
   "source": [
    "data['50th'] = fifty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c0d1cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:18:30.303491Z",
     "start_time": "2023-12-10T13:16:42.462217Z"
    }
   },
   "outputs": [],
   "source": [
    "seventyfive = [np.nanpercentile(i, 75) for i in tqdm(tb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef3bda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:18:30.777903Z",
     "start_time": "2023-12-10T13:18:30.305104Z"
    }
   },
   "outputs": [],
   "source": [
    "data['75th'] = seventyfive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05f15f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:20:17.116035Z",
     "start_time": "2023-12-10T13:18:30.779571Z"
    }
   },
   "outputs": [],
   "source": [
    "ninety = [np.nanpercentile(i, 90) for i in tqdm(tb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf15d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:20:17.284260Z",
     "start_time": "2023-12-10T13:20:17.117710Z"
    }
   },
   "outputs": [],
   "source": [
    "data['90th'] = ninety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dba610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:22:03.077606Z",
     "start_time": "2023-12-10T13:20:17.285922Z"
    }
   },
   "outputs": [],
   "source": [
    "ninetyfive = [np.nanpercentile(i, 95) for i in tqdm(tb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa43246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:22:03.254064Z",
     "start_time": "2023-12-10T13:22:03.079324Z"
    }
   },
   "outputs": [],
   "source": [
    "data['95th'] = ninetyfive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafaa618",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:23:48.638171Z",
     "start_time": "2023-12-10T13:22:03.255791Z"
    }
   },
   "outputs": [],
   "source": [
    "ninetynine = [np.nanpercentile(i, 99) for i in tqdm(tb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ba671",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:23:48.793952Z",
     "start_time": "2023-12-10T13:23:48.639891Z"
    }
   },
   "outputs": [],
   "source": [
    "data['99th'] = ninetynine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d539ea4",
   "metadata": {},
   "source": [
    "# Continuing calculation of other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3201a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:25:17.159999Z",
     "start_time": "2023-12-10T13:23:48.795586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate standard deviation of brightness temperature\n",
    "# Create a new column with the standard deviation of each list\n",
    "data['std_dev_tb'] = data['TB'].apply(np.nanstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215eff9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:27:34.384523Z",
     "start_time": "2023-12-10T13:25:17.161615Z"
    }
   },
   "outputs": [],
   "source": [
    "radius_earth = 6371  # Earth's radius in kilometers\n",
    "degree_to_radian = math.pi / 180.0\n",
    "constant = 0.1*0.1*(2 * math.pi * radius_earth / 360)*(2 * math.pi * radius_earth / 360)\n",
    "def calculate_radius(lat_degrees, pixel_count):\n",
    "    # Convert latitude from degrees to radians\n",
    "    lat_radians = lat_degrees * degree_to_radian\n",
    "    # Calculate the area\n",
    "    area = math.cos(lat_radians)*constant*pixel_count\n",
    "    radius = np.sqrt(area/math.pi)\n",
    "    return radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65d54bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:33:32.385119Z",
     "start_time": "2023-12-10T13:27:34.393347Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the function to create the 'radius2' column\n",
    "data['radius'] = data.apply(lambda row: calculate_radius(row['latitude'], row['pixel_count']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a7d124",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:33:32.497150Z",
     "start_time": "2023-12-10T13:33:32.395400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find maximum radius of each convective family\n",
    "dfc = data.groupby('cell')['radius']\n",
    "data['max_radius_cell' ] = dfc.transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f1cc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:36:31.996263Z",
     "start_time": "2023-12-10T13:33:32.500621Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate total hours and add as a new column\n",
    "data['total_hours'] = data['time_cell'].apply(lambda td: td.days * 24 + td.seconds // 3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669ee14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:36:32.081070Z",
     "start_time": "2023-12-10T13:36:31.999881Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate maximum duration of each convective family\n",
    "dfc = data.groupby('cell')['total_hours']\n",
    "data['lifetime_hours' ] = dfc.transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15211f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:36:32.147048Z",
     "start_time": "2023-12-10T13:36:32.085488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate duration/lifetime of each convective family as number of convective system it contains.\n",
    "dfc = data.groupby('cell')['feature']\n",
    "data['lifetime_num_cs' ] = dfc.transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b63172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:38:24.734465Z",
     "start_time": "2023-12-10T13:36:32.149799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate average optical thickness of CS (convective system)\n",
    "data['avg_optical_thickness'] = data['TAU'].apply(np.nanmean)\n",
    "# Calculate maximum optical thickness of CS (convective system)\n",
    "data['max_optical_thickness'] = data['TAU'].apply(np.nanmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c8a743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:47:29.836433Z",
     "start_time": "2023-12-10T13:38:24.736351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Squared correlation of latitude and longitude within convective system\n",
    "data['squared_corr'] = data.apply(lambda row: (np.corrcoef(row['pixel_lats'],row['pixel_lons'])[0,1])**2,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73308708",
   "metadata": {},
   "source": [
    "# Calculating wind speed and wind direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59935d7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:47:29.849865Z",
     "start_time": "2023-12-10T13:47:29.839248Z"
    }
   },
   "outputs": [],
   "source": [
    "def wind_speed(lat1, lon1, lat2, lon2):\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "    # Radius of the Earth in kilometers\n",
    "    earth_radius = 6371.0\n",
    "    # Haversine formula\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    distance = earth_radius * c\n",
    "    speed_kmh = distance/3\n",
    "    speed_ms = speed_kmh * (5/18)\n",
    "    return speed_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bf16cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T13:53:09.086424Z",
     "start_time": "2023-12-10T13:47:29.853521Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate wind speed for each cell's (convective family's) consecutive latitude and longitude pairs\n",
    "def calculate_wind_speed(group):\n",
    "    speeds = []\n",
    "    total = len(group) - 1\n",
    "    for i in range(total):\n",
    "        lat1, lon1 = group.iloc[i]['latitude'], group.iloc[i]['longitude']\n",
    "        lat2, lon2 = group.iloc[i + 1]['latitude'], group.iloc[i + 1]['longitude']\n",
    "        speeds.append(wind_speed(lat1, lon1, lat2, lon2))\n",
    "    speeds.append(np.nan)  # Adding np.nan for the last row\n",
    "    return speeds\n",
    "\n",
    "# Apply the calculate_wind_speed function to each cell group\n",
    "result = data.groupby('cell').apply(calculate_wind_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597192d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T14:04:18.238203Z",
     "start_time": "2023-12-10T13:53:09.088073Z"
    }
   },
   "outputs": [],
   "source": [
    "# Update the wind speed values in the existing dataframe based on wind_speed_series\n",
    "for cell, wind_speed_list in tqdm(result.items()):\n",
    "    row_indices = data[data['cell'] == cell].index\n",
    "    for i, wind_speed in enumerate(wind_speed_list):\n",
    "        data.at[row_indices[i], 'wind_speed'] = wind_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf1d8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T14:04:18.243450Z",
     "start_time": "2023-12-10T14:04:18.239999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert wind directions from degrees to letters\n",
    "def wind_direction_to_letter(degrees):\n",
    "    if pd.notna(degrees):  # Check if the value is not NaN\n",
    "        directions = [\"N\", \"NNE\", \"NE\", \"ENE\", \"E\", \"ESE\", \"SE\", \"SSE\", \"S\", \"SSW\", \"SW\", \"WSW\", \"W\", \"WNW\", \"NW\", \"NNW\"]\n",
    "        index = int((degrees + 11.25) % 360 / 22.5)\n",
    "        return directions[index]\n",
    "    else:\n",
    "        return np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c17b9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T14:18:02.924197Z",
     "start_time": "2023-12-10T14:04:18.244995Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create empty list to append wind direction values to\n",
    "wind_directions = []\n",
    "# Iterate over rows to calculate wind direction of consecutive convection systems\n",
    "for i,row in data.iterrows():\n",
    "    try:\n",
    "        u_wind = data.iloc[i]['longitude'] - data.iloc[i+1]['longitude']\n",
    "        v_wind = data.iloc[i]['latitude'] - data.iloc[i+1]['latitude']\n",
    "        angle_radians = math.atan2(u_wind, v_wind)\n",
    "        angle_degrees = math.degrees(angle_radians)\n",
    "        angle_degrees = angle_degrees % 360# Convert to direction with respect to north\n",
    "        wind_directions.append(angle_degrees)\n",
    "    except:\n",
    "        pass\n",
    "wind_directions.append(np.nan) #instead of the last row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf22fd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T14:18:03.071323Z",
     "start_time": "2023-12-10T14:18:02.931502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add values from the list as a dataframe column\n",
    "data['wind_dir'] = wind_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c956a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T14:24:16.987809Z",
     "start_time": "2023-12-10T14:18:03.074372Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to replace last values with NaN\n",
    "def replace_last_with_nan(column):\n",
    "    column.iloc[-1] = np.nan\n",
    "    return column\n",
    "\n",
    "# Group by 'cell' column and apply the above function\n",
    "data['wind_dir'] = data.groupby('cell')['wind_dir'].apply(replace_last_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec21ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T14:24:17.723992Z",
     "start_time": "2023-12-10T14:24:16.993272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply function to convert wind directions from degress to letters\n",
    "data['wind_dir_letter'] = data['wind_dir'].apply(wind_direction_to_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e532eec",
   "metadata": {},
   "source": [
    "# Calculation of miscellaneous parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bca4b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T14:24:51.461361Z",
     "start_time": "2023-12-10T14:24:17.726207Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate the minimum value from a list\n",
    "def calculate_min(lst):\n",
    "    return min(lst) if isinstance(lst, list) else None\n",
    "# Function to calculate the maximum value from a list\n",
    "def calculate_max(lst):\n",
    "    return max(lst) if isinstance(lst, list) else None\n",
    "# Apply the function to determine minimum and maximum coordinates of each convective system\n",
    "data['min_lat'] = data['pixel_lats'].apply(calculate_min)\n",
    "data['max_lat'] = data['pixel_lats'].apply(calculate_max)\n",
    "data['min_lon'] = data['pixel_lons'].apply(calculate_min)\n",
    "data['max_lon'] = data['pixel_lons'].apply(calculate_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb088137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T14:24:51.788887Z",
     "start_time": "2023-12-10T14:24:51.464537Z"
    }
   },
   "outputs": [],
   "source": [
    "latitudes = list(data['pixel_lats'])\n",
    "longitudes = list(data['pixel_lons'])\n",
    "# Function to process every convective system and determine land/water mask\n",
    "# More infromation about global_land_mask module that was used to determine\n",
    "# whether a datapoint is located over land or water can be found here:\n",
    "# https://github.com/toddkarin/global-land-mask\n",
    "def process_row(latitude_list, longitude_list):\n",
    "    if isinstance(latitude_list, list) and isinstance(longitude_list, list):\n",
    "        longitude_list = [l - 180 for l in longitude_list]\n",
    "        lat_lon = [globe.is_land(la, lo) for la, lo in zip(latitude_list, longitude_list)]\n",
    "        outcome_counts = Counter(lat_lon)\n",
    "        majority_outcome = max(outcome_counts, key=outcome_counts.get)\n",
    "        return majority_outcome\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaef520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T14:24:52.026467Z",
     "start_time": "2023-12-10T14:24:51.793653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting data into chucks for smoother processing\n",
    "chunk_size = 10000\n",
    "chunks_lats = [latitudes[i:i + chunk_size] for i in range(0, len(latitudes), chunk_size)]\n",
    "chunks_lons = [longitudes[i:i + chunk_size] for i in range(0, len(longitudes), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70ccc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:30.650643Z",
     "start_time": "2023-12-10T14:24:52.028139Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using parallel processing and appending results to 'land_water_results' list\n",
    "land_water_results = []\n",
    "for lats, lons in zip(chunks_lats, chunks_lons):\n",
    "    with concurrent.futures.ProcessPoolExecutor(mp_context=mp.get_context('fork'), max_workers=28) as executor:\n",
    "        results = list(notebook.tqdm(executor.map(process_row, lats, lons), total=len(lats)))\n",
    "        land_water_results.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec94632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:30.928151Z",
     "start_time": "2023-12-10T16:00:30.658420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate a list of lists\n",
    "merged_list = sum(land_water_results, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b2d45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:31.156890Z",
     "start_time": "2023-12-10T16:00:30.930291Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add the new list as a new column\n",
    "data['land_water_mask'] = merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf7ba02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T16:00:32.652380Z",
     "start_time": "2023-12-10T16:00:31.158966Z"
    }
   },
   "outputs": [],
   "source": [
    "# Replace True and False values with land and water values respectively\n",
    "data['land_water_mask'] = data['land_water_mask'].replace({True: 'land', False: 'water'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feae402",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:30:49.655272Z",
     "start_time": "2023-12-10T16:00:32.655811Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining function to calculate overlap between convective system and using parallel processing to process the data\n",
    "def calculate_overlap(index):\n",
    "    try:\n",
    "        if isinstance(data.iloc[index]['pixel_lons'], list) and isinstance(data.iloc[index + 1]['pixel_lons'], list):\n",
    "            list1 = [*zip(data.iloc[index]['pixel_lons'], data.iloc[index]['pixel_lats'])]\n",
    "            list2 = [*zip(data.iloc[index + 1]['pixel_lons'], data.iloc[index + 1]['pixel_lats'])]\n",
    "            coinciding_count = sum(tuple1 in list2 for tuple1 in list1)\n",
    "            biggest_cs = max(len(data.iloc[index]['pixel_lons']), len(data.iloc[index + 1]['pixel_lons']))\n",
    "            percent_overlap = coinciding_count / biggest_cs * 100\n",
    "            return percent_overlap\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "chunk_size = 10000\n",
    "inds = data.index.values\n",
    "chunk_inds = [inds[i:i + chunk_size] for i in range(0, len(inds), chunk_size)]\n",
    "\n",
    "percent_overlap = []\n",
    "for ind in chunk_inds:\n",
    "    with concurrent.futures.ProcessPoolExecutor(mp_context=mp.get_context('fork'), max_workers=28) as executor:\n",
    "        results = list(notebook.tqdm(executor.map(calculate_overlap, ind), total=len(ind)))\n",
    "        percent_overlap.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609fd82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:30:51.036332Z",
     "start_time": "2023-12-10T17:30:49.664489Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fdd024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:30:51.625571Z",
     "start_time": "2023-12-10T17:30:51.037901Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate a list of lists\n",
    "merged_list = sum(percent_overlap, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28843e02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:30:51.762161Z",
     "start_time": "2023-12-10T17:30:51.627984Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add the new list as a new column\n",
    "data['percent_overlap'] = merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58069866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:37:21.193409Z",
     "start_time": "2023-12-10T17:30:51.764548Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to replace last convective system of each convective family with NaN\n",
    "def replace_last_with_nan(column):\n",
    "    column.iloc[-1] = np.nan\n",
    "    return column\n",
    "\n",
    "# Group by 'cell' column and apply the custom function\n",
    "data['percent_overlap'] = data.groupby('cell')['percent_overlap'].apply(replace_last_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f64a78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:37:21.250503Z",
     "start_time": "2023-12-10T17:37:21.199781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate percent non overlap between consecutive convective systems\n",
    "data['percent_non_overlap'] = 100 - data['percent_overlap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1954c6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:37:22.112934Z",
     "start_time": "2023-12-10T17:37:21.252250Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be283065",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:37:25.437170Z",
     "start_time": "2023-12-10T17:37:22.115043Z"
    }
   },
   "outputs": [],
   "source": [
    "data2 = data.dropna(subset=['pixel_lats', 'pixel_lons', 'TB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf971f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:37:25.450780Z",
     "start_time": "2023-12-10T17:37:25.438802Z"
    }
   },
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance between two points on the Earth's surface\n",
    "    specified in decimal degrees of latitude and longitude.\n",
    "\n",
    "    :param lat1: Latitude of the first point\n",
    "    :param lon1: Longitude of the first point\n",
    "    :param lat2: Latitude of the second point\n",
    "    :param lon2: Longitude of the second point\n",
    "    :return: Haversine distance in kilometers\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    radius_of_earth = 6371  # Earth's radius in kilometers\n",
    "    distance = radius_of_earth * c\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f491118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:37:25.456656Z",
     "start_time": "2023-12-10T17:37:25.452465Z"
    }
   },
   "outputs": [],
   "source": [
    "# The spatial gradient of convective systems\n",
    "# Determined by the maximum and minimum temperature and their separation distance, K/km)\n",
    "def calculate_gradient(row):\n",
    "    diff = abs(min(row['TB']) - max(row['TB']))\n",
    "    distance = haversine_distance(row['min_lat'], row['min_lon'], row['max_lat'], row['max_lon'])\n",
    "    if distance == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    res = (diff / distance) * 1000\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3e6a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:41:40.524542Z",
     "start_time": "2023-12-10T17:37:25.459070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use tqdm with progress_apply to apply the function and display a progress bar\n",
    "tqdm.pandas(desc=\"Processing\")\n",
    "data2['cs_gradient'] = data2.progress_apply(calculate_gradient, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de812c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:41:40.759265Z",
     "start_time": "2023-12-10T17:41:40.527755Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary from the DataFrame\n",
    "gradient_dict = dict(zip(data2['feature'], data2['cs_gradient']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9e97a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:41:41.096893Z",
     "start_time": "2023-12-10T17:41:40.761262Z"
    }
   },
   "outputs": [],
   "source": [
    "data['cs_gradient'] = data.feature.map(gradient_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b881aa11",
   "metadata": {},
   "source": [
    "# Calculate ellipse parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e106cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:41:41.759346Z",
     "start_time": "2023-12-10T17:41:41.099542Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6478ee91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:42:44.051267Z",
     "start_time": "2023-12-10T17:41:41.786306Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find central latitude of each CS (convectvie system)\n",
    "data['central_latitude'] = data['pixel_lats'].apply(np.nanmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c244d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:43:46.185764Z",
     "start_time": "2023-12-10T17:42:44.052704Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find central longitude of each CS (convectvie system)\n",
    "data['central_longitude'] = data['pixel_lons'].apply(np.nanmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c6b454",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:43:46.196556Z",
     "start_time": "2023-12-10T17:43:46.187425Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_major_minor_params(lats,lons):\n",
    "     # Check for empty lists or NaN values\n",
    "    if not isinstance(lats, list) or not isinstance(lons, list) or len(lats) == 1 or len(lons) == 1:\n",
    "        return np.nan, np.nan,np.nan\n",
    "    \n",
    "    # Combine latitude and longitude into a single NumPy array\n",
    "    points = np.array(list(zip(lats, lons)))\n",
    "\n",
    "    # Perform Principal Component Analysis (PCA)\n",
    "    # Reshape points array to ensure it's 2D\n",
    "    points = points.reshape((-1, 2))\n",
    "\n",
    "    covariance_matrix = np.cov(points, rowvar=False)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "    # Calculate semi-major and semi-minor axes\n",
    "    semi_major = 2 * np.sqrt(eigenvalues[0])  # Largest eigenvalue\n",
    "    semi_minor = 2 * np.sqrt(eigenvalues[1])  # Second largest eigenvalue\n",
    "    # Calculate inclination of the major axis\n",
    "    inclination = np.degrees(np.arctan2(eigenvectors[1, 1], eigenvectors[0, 1]))\n",
    "\n",
    "    return semi_major, semi_minor,inclination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a1e097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:43:46.237384Z",
     "start_time": "2023-12-10T17:43:46.198453Z"
    }
   },
   "outputs": [],
   "source": [
    "latitudes = data['pixel_lats']\n",
    "longitudes = data['pixel_lons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f561b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:50:51.829809Z",
     "start_time": "2023-12-10T17:43:46.239273Z"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for a,b in tqdm(zip(latitudes,longitudes)):\n",
    "    r = calculate_major_minor_params(a,b)\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e78c33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:50:52.326956Z",
     "start_time": "2023-12-10T17:50:51.831987Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with columns 'semi_major', 'semi_minor', 'inclination'\n",
    "new_df = pd.DataFrame(results, columns=['semi_major', 'semi_minor', 'inclination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8210838c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:50:53.190016Z",
     "start_time": "2023-12-10T17:50:52.328610Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data, new_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825dde0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:50:53.210154Z",
     "start_time": "2023-12-10T17:50:53.191695Z"
    }
   },
   "outputs": [],
   "source": [
    "data['eccentricity'] = np.sqrt(np.square(data['semi_major']) - np.square(data['semi_minor'])) / data['semi_major']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faf5d32",
   "metadata": {},
   "source": [
    "# Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b875f076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:50:54.216164Z",
     "start_time": "2023-12-10T17:50:53.211652Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove redundant columns\n",
    "data = data.drop(columns=['timestr','TB','TAU','pixel_lats','pixel_lons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c305e04",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:50:56.082472Z",
     "start_time": "2023-12-10T17:50:54.217913Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame and 'time' column contains datetime.time objects\n",
    "data['time'] = data['time'].apply(lambda x: x.strftime('%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d111ea53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:51:43.655858Z",
     "start_time": "2023-12-10T17:50:58.620253Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(f'{year}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b9723",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:51:43.694925Z",
     "start_time": "2023-12-10T17:51:43.657460Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = xr.Dataset.from_dataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b27e5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:51:43.699105Z",
     "start_time": "2023-12-10T17:51:43.696833Z"
    }
   },
   "outputs": [],
   "source": [
    "netcdf_file_path = f'{year}.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298c266b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T17:52:16.406331Z",
     "start_time": "2023-12-10T17:51:43.700736Z"
    }
   },
   "outputs": [],
   "source": [
    "ds.to_netcdf(netcdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a3d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbe0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa080d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
